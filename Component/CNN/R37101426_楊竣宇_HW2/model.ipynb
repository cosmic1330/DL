{"cells":[{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# windows\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sn\n","from sklearn.utils import shuffle\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","import os\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, Activation, MaxPooling2D, Flatten, Dropout, BatchNormalization\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.optimizers import RMSprop, Adadelta, Adam, SGD\n","from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy\n","import tensorflow as tf\n","tf.device(\"/device:GPU:0\")\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n","\n","# common\n","\n","# 讀取資料－２\n","# training data path\n","trcloudy = '/Users/yangjunyu/py_project/DL/Component/weatherImage/train/cloudy'\n","trrain = '/Users/yangjunyu/py_project/DL/Component/weatherImage/train/rain'\n","trshine = '/Users/yangjunyu/py_project/DL/Component/weatherImage/train/shine'\n","trsunrise = '/Users/yangjunyu/py_project/DL/Component/weatherImage/train/sunrise'\n","# testing data path\n","testpath = '/Users/yangjunyu/py_project/DL/Component/weatherImage/test'\n","\n","# 顯示資料筆數\n","print('train cloudy length: ', len(os.listdir(trcloudy)))\n","print('train rain length: ', len(os.listdir(trrain)))\n","print('train shine length: ', len(os.listdir(trshine)))\n","print('train sunrise length: ', len(os.listdir(trsunrise)))\n","print('test data length: ', len(os.listdir(testpath)))\n","print('\\n')\n","\n","# convert image data to numpy\n","def convertImageToNumpy(list):\n","    data = []\n","    x = 0\n","    label = []\n","    fileNames = []\n","    for index, url in enumerate(list):\n","        for i in range(len(os.listdir(url))):\n","            fileName = os.listdir(url)[i]\n","            img = cv2.imread(url+f\"/{fileName}\")\n","            img = cv2.resize(img, (128,128))\n","            img = img[:, :, ::-1]/255\n","            data.append(img)\n","            label.append(index)\n","            fileNames.append(fileName)\n","            x += 1\n","    label = np.array(label)\n","    data = np.array(data)\n","    return data, label, fileNames\n","\n","\n","# 取得資料夾資料\n","trainData, trainLabel, trainFileNames = convertImageToNumpy(\n","    list=[trcloudy, trrain, trshine, trsunrise])\n","testData, testLabel, testFileNames = convertImageToNumpy(list=[testpath])\n","\n","# on-hot label\n","trainLabel = to_categorical(trainLabel)\n","\n","\n","# define model\n","cnn = Sequential()\n","cnn.add(\n","    Conv2D(\n","        64, (3, 3),\n","        input_shape=(128,128, 3),\n","        kernel_regularizer=regularizers.l2(0.001),padding='same'))\n","\n","cnn.add(BatchNormalization())\n","cnn.add(Activation(\"relu\"))\n","cnn.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n","cnn.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n","\n","cnn.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","cnn.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","cnn.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n","\n","cnn.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n","cnn.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n","cnn.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n","cnn.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n","cnn.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","cnn.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","cnn.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","cnn.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","cnn.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","cnn.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","cnn.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","cnn.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","cnn.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","cnn.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","cnn.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","\n","cnn.add(Flatten())\n","cnn.add(Dropout(0.25))\n","cnn.add(Dense(units=4,activation='softmax'))\n","# show the model structure\n","cnn.summary()\n","\n","my_callbacks = [\n","    # validation loss 4個執行週期沒改善就停止訓練\n","    # EarlyStopping(patience=4, monitor='val_accuracy'),\n","    # save the best weights\n","    # ModelCheckpoint(\n","        # filepath=\"/Users/yangjunyu/py_project/DL/Component/CNN/R37101426_楊竣宇_HW2/myModel_weight.h5\", verbose=1,\n","        # save_best_only=True)\n","]\n","\n","# comiple model\n","batch_size = 64\n","epochs = 100\n","optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.015, amsgrad=False)\n","# optimizer = RMSprop(learning_rate = 0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n","# optimizer = Adadelta(learning_rate=1.0, rho=0.95, epsilon=None, decay=0.0)\n","# optimizer = SGD(learning_rate=0.01, momentum=0.0, decay=0.0, nesterov=False)\n","cnn.compile(optimizer=optimizer, loss=\"categorical_crossentropy\",\n","            metrics=['accuracy'])\n","\n","# cross validation\n","acc_list = []\n","loss_list = []\n","counter = 1\n","for index in range(0, 1):\n","    # 打亂資料順序\n","    tr_data, tr_label = shuffle(trainData, trainLabel)\n","    # 準備此次的資料\n","    train_data = tr_data[0:786]\n","    val_data = tr_data[786:]\n","    train_label = tr_label[0:786]\n","    val_label = tr_label[786:]\n","\n","    # # 映出圖片\n","    # cv2.imshow(f'train_label-{train_label[0]}',train_data[0])\n","    # cv2.imshow(f'train_label-{val_label[0]}',val_data[0])\n","    # cv2.waitKey(0)\n","\n","    #  資料增生\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # 以每一張feature map為單位將平均值設為0\n","        samplewise_center=False,  # set each sample mean to 0\n","        # 以每一張feature map為單位將數值除以其標準差(上述兩步驟就是我們常見的Standardization)\n","        featurewise_std_normalization=False,\n","        samplewise_std_normalization=False,  # 將输入的每個樣本除以其自身的標準差。\n","        zca_whitening=False,  # dimesion reduction\n","        rotation_range=0.1,  # 隨機旋轉圖片\n","        zoom_range=0.1,  # 隨機縮放範圍\n","        width_shift_range=0.1,  # 水平平移，相對總寬度的比例\n","        height_shift_range=0.1,  # 垂直平移，相對總高度的比例\n","        horizontal_flip=False,  # 一半影象水平翻轉\n","        vertical_flip=False)  # 一半影象垂直翻轉\n","    # datagen.fit(train_data)\n","\n","    fake = datagen.flow(train_data, train_label, batch_size=batch_size)\n","    print(\"len:\",fake[0][0].shape)\n","    break\n","\n","    # 使用此次訓練資料訓練\n","    history = cnn.fit(\n","        datagen.flow(train_data, train_label, batch_size=batch_size),\n","        epochs=epochs,\n","        validation_data=(val_data, val_label),\n","        steps_per_epoch=train_data.shape[0] // batch_size,\n","        validation_steps=val_data.shape[0] // batch_size,\n","        callbacks=my_callbacks)\n","\n","    # 繪圖\n","    fit = plt.figure(figsize=(10, 10))\n","    plt.subplot(5, 3, counter)\n","    plt.plot(history.history['loss'], label='loss')\n","    plt.plot(history.history['val_loss'], label='val_loss')\n","    plt.title('loss curve')\n","    plt.ylabel('loss')\n","    plt.legend()\n","    plt.subplot(5, 3, counter+1)\n","    plt.plot(history.history['accuracy'], label='accuracy')\n","    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n","    plt.title('accuracy curve')\n","    plt.ylabel('accuracy')\n","    plt.legend()\n","\n","    # 混淆舉證\n","    pre = cnn.predict(val_data)\n","    pre = np.argmax(pre, axis=1)\n","    cm = confusion_matrix(pre, np.argmax(val_label, axis=1))\n","    plt.subplot(5, 3, counter+2)\n","    plt.title('confusion matrix')\n","    sn.heatmap(cm, annot=True, cmap='OrRd', fmt='g')\n","    plt.xlabel('prediction')\n","    plt.ylabel('true label')\n","\n","    #  圖檔位置\n","    counter+3\n","\n","    #  計算loss\n","    score = cnn.evaluate(val_data,val_label)\n","    print(\"Test Loss:\",score[0])\n","    print(\"Test Accuracy:\",score[1])\n","\n","plt.savefig('/Users/yangjunyu/py_project/DL/Component/CNN/R37101426_楊竣宇_HW2/output.png')\n","plt.show()\n","cnn.save('/Users/yangjunyu/py_project/DL/Component/CNN/R37101426_楊竣宇_HW2/myModel.h5') \n","\n","\n","# 結果轉csv檔\n","prediction = cnn.predict(testData)\n","prediction = np.argmax(prediction,axis=1)\n","test_label = pd.DataFrame()\n","test_label['image_id']=testFileNames\n","test_label['labels']=prediction\n","test_label=test_label.sort_values(by='image_id')\n","test_label.to_csv('/Users/yangjunyu/py_project/DL/Component/CNN/R37101426_楊竣宇_HW2/predict_label.csv',index=False)\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"interpreter":{"hash":"4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"},"kernelspec":{"display_name":"Python 3.8.13 ('tensorflow')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
